<!DOCTYPE html>
<html lang="en-EN">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta content="keyword 1, keyword 2, keyword 3" name="keywords">
<meta content="Ritchie Vink" name="author">
<meta property="og:title" content="Variational inference from scratch - Ritchie Vink">
<meta property="og:url" content="https://www.ritchievink.com/blog/2019/09/16/variational-inference-from-scratch/">
<meta property="og:description" content="">
<meta property="og:type" content="website" />


<meta property="og:image" content="https://www.ritchievink.com/img/post-27-vi-from-scratch/soundboard.jpg" />


<title>Variational inference from scratch | Ritchie Vink</title>

<link rel="stylesheet" href="https://www.ritchievink.com//css/style.css">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />

<link rel="stylesheet"
      href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.0/build/styles/default.min.css">

</head>

<body>
<section class="section">
  <div class="container">
    <nav class="nav">

 <img src="../../../../../profile.jpg" alt="Avatar" style="margin-right: 1em" height="100px"> 
      <div class="nav-left" style="flex-basis: auto;">

        <a class="nav-item" href="https://www.ritchievink.com/"><h1 class="title is-4">Ritchie Vink</h1></a>
      <nav class="nav-item level is-mobile">
          <a class="level-item" href="../../../../../tags">
            tags
          </a>
          
          
          <a class="level-item" href="https://www.ritchievink.com/about/">
            about
          </a>
          
          <a class="level-item" href="https://www.ritchievink.com/anastruct/">
            anastruct
          </a>
          
        </nav>
      </div>
      <div class="nav-right">
        <nav class="nav-item level is-mobile">
          
          <a class="level-item" href="https://github.com/ritchie46" target="_blank">
            <span class="icon">
              <i class="fa fa-github"></i>
            </span>
          </a>
          
          <a class="level-item" href="https://linkedin.com/in/ritchievink/" target="_blank">
            <span class="icon">
              <i class="fa fa-linkedin-square"></i>
            </span>
          </a>
          
          <a class="level-item" href="https://www.ritchievink.com/index.xml" target="_blank">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>
          </a>
          
        </nav>
      </div>
    </nav>
  </div>
</section>

<section class="section">
  <div class="container">
    <h1 class="title">Variational inference from scratch</h1>
    <h2 class="subtitle is-5">September 16, 2019 by Ritchie Vink</h2>
    
      <div class="tags">
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/algorithm-breakdown">algorithm breakdown</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/machine-learning">machine learning</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/python">python</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/bayesian">bayesian</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/optimization">optimization</a>
    
</div>

    
    <div class="content">
      <figure><img src="../../../../../img/post-27-vi-from-scratch/soundboard.jpg"/>
</figure>

<p>In the posts <a href="https://www.ritchievink.com/blog/2019/05/24/algorithm-breakdown-expectation-maximization/">Expectation Maximization</a> and <a href="https://www.ritchievink.com/blog/2019/06/10/bayesian-inference-how-we-are-able-to-chase-the-posterior/">Bayesian inference; How we are able to chase the Posterior</a>, we laid the mathematical foundation of variational inference. This post we will continue on that foundation and implement variational inference in Pytorch. If you are not familiar with the basis, I&rsquo;d recommend reading these posts to get you up to speed.</p>
<p>This post we&rsquo;ll model a probablistic layer as output layer of a neural network. This will give us insight in the aleatoric uncertainty (the noise in the data). We will evaluate the results on a fake dataset <a href="https://medium.com/tensorflow/regression-with-probabilistic-layers-in-tensorflow-probability-e46ff5d37baf">borrowed from this post</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch <span style="color:#f92672">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> datasets
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>w0 <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.125</span>
</span></span><span style="display:flex;"><span>b0 <span style="color:#f92672">=</span> <span style="color:#ae81ff">5.</span>
</span></span><span style="display:flex;"><span>x_range <span style="color:#f92672">=</span> [<span style="color:#f92672">-</span><span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">60</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_dataset</span>(n<span style="color:#f92672">=</span><span style="color:#ae81ff">150</span>, n_tst<span style="color:#f92672">=</span><span style="color:#ae81ff">150</span>):
</span></span><span style="display:flex;"><span>    np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">43</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">s</span>(x):
</span></span><span style="display:flex;"><span>        g <span style="color:#f92672">=</span> (x <span style="color:#f92672">-</span> x_range[<span style="color:#ae81ff">0</span>]) <span style="color:#f92672">/</span> (x_range[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> x_range[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">*</span> (<span style="color:#ae81ff">0.25</span> <span style="color:#f92672">+</span> g<span style="color:#f92672">**</span><span style="color:#ae81ff">2.</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> (x_range[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> x_range[<span style="color:#ae81ff">0</span>]) <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand(n) <span style="color:#f92672">+</span> x_range[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>    eps <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randn(n) <span style="color:#f92672">*</span> s(x)
</span></span><span style="display:flex;"><span>    y <span style="color:#f92672">=</span> (w0 <span style="color:#f92672">*</span> x <span style="color:#f92672">*</span> (<span style="color:#ae81ff">1.</span> <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>sin(x)) <span style="color:#f92672">+</span> b0) <span style="color:#f92672">+</span> eps
</span></span><span style="display:flex;"><span>    y <span style="color:#f92672">=</span> (y <span style="color:#f92672">-</span> y<span style="color:#f92672">.</span>mean()) <span style="color:#f92672">/</span> y<span style="color:#f92672">.</span>std()
</span></span><span style="display:flex;"><span>    idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argsort(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> x[idx]
</span></span><span style="display:flex;"><span>    y <span style="color:#f92672">=</span> y[idx]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> y[:, <span style="color:#66d9ef">None</span>], x[:, <span style="color:#66d9ef">None</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>y, x <span style="color:#f92672">=</span> load_dataset()
</span></span></code></pre></div><figure><img src="../../../../../img/post-27-vi-from-scratch/syndata.png"/><figcaption>
            <h4>Generated data with noise dependent on $X$.</h4>
        </figcaption>
</figure>

<h2 id="maximum-likelihood-estimate">Maximum likelihood estimate</h2>
<p>First we&rsquo;ll model a neural network $g_{\theta}(x)$ with maximum likelihood estimation. Where we assume a Gaussian likelihood.</p>
<p>$$\begin{equation}
y \sim \mathcal{N}(g_{\theta}(x), \sigma^2)
\end{equation}$$</p>
<div>$$ \begin{equation}\hat{\theta}_{\text{MLE}} = \text{argmax}_\theta \prod_i^nP(y_i|\theta) \end{equation}$$</div>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Go to pytorch world</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor(X, dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float)
</span></span><span style="display:flex;"><span>Y <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor(Y, dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MaximumLikelihood</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>out <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">20</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>out(x)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">200</span>
</span></span><span style="display:flex;"><span>m <span style="color:#f92672">=</span> MaximumLikelihood()
</span></span><span style="display:flex;"><span>optim <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(m<span style="color:#f92672">.</span>parameters(), lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epochs):
</span></span><span style="display:flex;"><span>    optim<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>    y_pred <span style="color:#f92672">=</span> m(X)
</span></span><span style="display:flex;"><span>    loss <span style="color:#f92672">=</span> (<span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> (y_pred <span style="color:#f92672">-</span> Y)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>    loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>    optim<span style="color:#f92672">.</span>step()
</span></span></code></pre></div><p>If we train this model, we might observe a regression line like below. We are able to predict the expectation of y, but we are not able to make a statement about the noise of our predictions. The outputs are point estimates.</p>
<figure><img src="../../../../../img/post-27-vi-from-scratch/fit_mle.png"/><figcaption>
            <h4>Fitted model with MLE.</h4>
        </figcaption>
</figure>

<h2 id="variational-regression">Variational regression</h2>
<p>Now let&rsquo;s consider a model where we want to  obtain the distribution $P(y|x) \propto P(x|y) P(y)$. In variational inference, we accept that we cannot obtain the true posterior $P(y|x)$, but we try to approximate this distribution with another distribution $Q_{\theta}(y)$, where $\theta$ are the variational parameters. This distribution we call a variational distribution.</p>
<p>If we choose a factorized (diagonal) Gaussian variational distribution, $Q_{\theta}(y)$ becomes $Q_{\theta}(\mu, \text{diag}(\sigma^2))$. <em>Note that we are now working with an 1D case and that this factorization doesn&rsquo;t mean much right now.</em> We want this distribution to be conditioned to $x$, therefore we define a function $g_{\theta}: x \mapsto \mu, \sigma$. The function $g_{\theta}$ will be a neural network that predicts the variational parameters. The total model can thus be described as:</p>
<p>$$ \begin{equation}P(y) = \mathcal{N}(0, 1) \end{equation}$$</p>
<p>$$ \begin{equation}Q(y|x) = \mathcal{N}(g_{\theta}(x)_{\mu}, \text{diag}(g_{\theta}(x)_{\sigma^2})))\end{equation}$$</p>
<p>Where we set a unit Gaussian prior $P(y)$.</p>
<h2 id="optimization-problem">Optimization problem</h2>
<p><em>Note: Above we&rsquo;ve defined the posterior and the variational distribution in the variable $y|x$, from now on we will generalize to a notation that is often used. We&rsquo;ll extend $y|x$ to any (latent) stochastic variable $Z$.</em></p>
<p>Variational inference is done by maximizing the ELBO (<strong>E</strong>vidence <strong>L</strong>ower <strong>BO</strong>und). Which is often written in a more intuitive form:</p>
<p>$$ \begin{equation}\text{argmax}_{Z} = E_{Z \sim Q}[\underbrace{\log P(D|Z)}_{\text{likelihood}}] - D_{KL}(Q(Z)||\underbrace{P(Z)}_{\text{prior}}) \label{eq:elbo} \end{equation}$$</p>
<p>Where we have a likelihood term (in Variational Autoencoders often called reconstruction loss) and the KL-divergence between the prior and the variational distribution. We are going to rewrite this ELBO definition so that it is more clear how we can use it to optimize the model, we&rsquo;ve just defined.</p>
<p>Let&rsquo;s first rewrite the KL-divergence term in integral form;</p>
<p>\begin{equation}E_{Z \sim Q}[\log P(D|Z)] + \int Q(Z) \frac{P(Z)}{Q(Z)}dZ \end{equation}</p>
<p><small><em>Note that the change of sign is due to the definition of the KL-divergence $D_{KL}(P||Q) = \int P(x) \log \frac{P(x)}{Q(x)}dx = -\int P(x) \log \frac{Q(x)}{P(x)}dx$</em>.</small></p>
<p>Now we observe that we can rewrite the integral form as an expectation $Z$;</p>
<p>\begin{equation} E_{Z \sim Q}[\log P(D|Z)] + E_{Z \sim Q}[ \frac{P(Z)}{Q(Z)}]dZ \end{equation}</p>
<p>And by applying the log rule $\log\frac{A}{B}=\log A - \log B$, we get;</p>
<p>\begin{equation} E_{Z \sim Q}[\log P(D|Z)] + E_{Z \sim Q}[\log P(Z) - \log Q(Z) ] \end{equation}</p>
<h2 id="monte-carlo-elbo">Monte Carlo ELBO</h2>
<p>Deriving those expectations can be some tedious mathematics, or maybe not even possible. Luckily we can get estimates of the mean by taking samples from $Q(Z)$ and average over those results.</p>
<h3 id="reparameterization-trick">Reparameterization trick</h3>
<p>If we start taking samples from a $Q(Z)$ we leave the deterministic world, and the gradient can not flow through the model anymore. We avoid this problem by reparameterizing the samples from the distribution.</p>
<p>Instead of sampling directly from the variational distribution;</p>
<p>\begin{equation} z \sim Q(\mu, \sigma^2) \end{equation}</p>
<p>We sample from a unit gaussian and recreate samples from the variational distribution. Now the stochasticity of $\epsilon$ is external and will not prevent the flow of gradients.</p>
<p>\begin{equation} z = \mu + \sigma \odot \epsilon \end{equation}</p>
<p>Where</p>
<p>\begin{equation} \epsilon \sim \mathcal{N}(0, 1) \end{equation}</p>
<h2 id="implementation">Implementation</h2>
<p>This is all we need for implementing and optimizing this model. Below we&rsquo;ll define the model in Pytorch. By calling the <code>forward</code> method we retrieve samples from the variational distribution.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">VI</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>q_mu <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">20</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">10</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>q_log_var <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">20</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">10</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">reparameterize</span>(self, mu, log_var):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># std can not be negative, thats why we use log variance</span>
</span></span><span style="display:flex;"><span>        sigma <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>exp(<span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> log_var) <span style="color:#f92672">+</span> <span style="color:#ae81ff">1e-5</span>
</span></span><span style="display:flex;"><span>        eps <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn_like(sigma)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> mu <span style="color:#f92672">+</span> sigma <span style="color:#f92672">*</span> eps
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        mu <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>q_mu(x)
</span></span><span style="display:flex;"><span>        log_var <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>q_log_var(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>reparameterize(mu, log_var), mu, log_var
</span></span></code></pre></div><p>The prior, the likelihood and the varitational distribution are all Gaussian, hence we only need to derive the log likelihood function for the Gaussian distribution.</p>
<p>\begin{equation} \mathcal{L}(\mu, \sigma, x)= -\frac{n}{2}(2\pi \sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n(x_i - \mu)^2 \end{equation}</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">ll_gaussian</span>(y, mu, log_var):
</span></span><span style="display:flex;"><span>    sigma <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>exp(<span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> log_var)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> torch<span style="color:#f92672">.</span>log(<span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>pi <span style="color:#f92672">*</span> sigma<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">-</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">/</span> (<span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> sigma<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>))<span style="color:#f92672">*</span> (y<span style="color:#f92672">-</span>mu)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
</span></span></code></pre></div><p>In the <code>elbo</code> function below, it all comes together. We compute the needed probabilities, and last we get an estimate of the expectation (see ELBO definition) by taking the means over a complete batch. In the <code>det_loss</code> function, we only reverse the sign, as all the optimizers in Pytorch are minimizers, not maximizers. And that is all we need, the result is an optimization problem with gradients. Hardly a problem at all in times of autograd.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">elbo</span>(y_pred, y, mu, log_var):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># likelihood of observing y given Variational mu and sigma</span>
</span></span><span style="display:flex;"><span>    likelihood <span style="color:#f92672">=</span> ll_gaussian(y, mu, log_var)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># prior probability of y_pred</span>
</span></span><span style="display:flex;"><span>    log_prior <span style="color:#f92672">=</span> ll_gaussian(y_pred, <span style="color:#ae81ff">0</span>, torch<span style="color:#f92672">.</span>log(torch<span style="color:#f92672">.</span>tensor(<span style="color:#ae81ff">1.</span>)))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># variational probability of y_pred</span>
</span></span><span style="display:flex;"><span>    log_p_q <span style="color:#f92672">=</span> ll_gaussian(y_pred, mu, log_var)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># by taking the mean we approximate the expectation</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> (likelihood <span style="color:#f92672">+</span> log_prior <span style="color:#f92672">-</span> log_p_q)<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">det_loss</span>(y_pred, y, mu, log_var):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#f92672">-</span>elbo(y_pred, y, mu, log_var)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">1500</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>m <span style="color:#f92672">=</span> VI()
</span></span><span style="display:flex;"><span>optim <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(m<span style="color:#f92672">.</span>parameters(), lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.005</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epochs):
</span></span><span style="display:flex;"><span>    optim<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>    y_pred, mu, log_var <span style="color:#f92672">=</span> m(X)
</span></span><span style="display:flex;"><span>    loss <span style="color:#f92672">=</span> det_loss(y_pred, Y, mu, log_var)
</span></span><span style="display:flex;"><span>    loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>    optim<span style="color:#f92672">.</span>step()
</span></span></code></pre></div><p>With the fitted model, we can draw samples from the approximate posterior. As we see in the plot below, the aleatoric uncertainty is incorporated in the model.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># draw samples from Q(theta)</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>    y_pred <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([m(X)[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1000</span>)], dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get some quantiles</span>
</span></span><span style="display:flex;"><span>q1, mu, q2 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>quantile(y_pred, [<span style="color:#ae81ff">0.05</span>, <span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">0.95</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">6</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(X, Y)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(X, mu)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>fill_between(X<span style="color:#f92672">.</span>flatten(), q1, q2, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)
</span></span></code></pre></div><figure><img src="../../../../../img/post-27-vi-from-scratch/fit_vi.png"/><figcaption>
            <h4>90% credible interval of $P(y|x)$.</h4>
        </figcaption>
</figure>

<h2 id="analytical-kl-divergence-and-reconstruction-loss">Analytical KL-divergence and reconstruction loss</h2>
<p>Above we have implemented ELBO by sampling from the variational posterior. It turns out that for the KL-divergence term, this isn&rsquo;t necessary as there is an analytical solution. <a href="https://arxiv.org/pdf/1312.6114.pdf">For the Gaussian case, Diederik P. Kingma and Max Welling (2013.  Auto-encoding variational bayes)</a> included the solution in Appendix B.</p>
<p>\begin{equation}  D_{KL}(Q(Z)||P(Z)) = \frac{1}{2}\sum_{i=1}^n(1+\log \sigma_i^2 - \mu_i^2 - \sigma_i^2) \end{equation}</p>
<p>For the likelihood term, we did implement Guassian log likelihood, this term can also be replaced with a similar loss functions. For Gaussian likelihood we can use squared mean error loss, for Bernoulli likelihood we could use binary cross entropy etc. If we do that for the earlier defined model, we can replace the loss function as defined below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">det_loss</span>(y, y_pred, mu, log_var):    
</span></span><span style="display:flex;"><span>    reconstruction_error <span style="color:#f92672">=</span> (<span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> (y <span style="color:#f92672">-</span> y_pred)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>sum()
</span></span><span style="display:flex;"><span>    kl_divergence <span style="color:#f92672">=</span> (<span style="color:#f92672">-</span><span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> torch<span style="color:#f92672">.</span>sum(<span style="color:#ae81ff">1</span> <span style="color:#f92672">+</span> log_var <span style="color:#f92672">-</span> mu<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> log_var<span style="color:#f92672">.</span>exp()))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> (reconstruction_error <span style="color:#f92672">+</span> kl_divergence)<span style="color:#f92672">.</span>sum()
</span></span></code></pre></div><h2 id="aleatoric-and-epistemic-uncertainty">Aleatoric and epistemic uncertainty</h2>
<p><em>Update September 27, 2019</em></p>
<p>In the example above we have used variational inference to infer $y$ by setting an approximating distribution $Q_{\theta}(Y)$. Next we&rsquo;ve defined a neural network capable of parameterizing this variational distribution $ f: \mathbb{R}^d \mapsto \mathbb{R}^n, \quad f(x) = \theta $, where $\theta = \{ \mu, \sigma \}$. By inherently modelling $\mu$ and $\sigma$ as a dependency on $X$, we were able to model the <strong>aleatoric</strong> uncertainty. This kind of uncertainty is called statistical uncertainty. This is the inherent variance in the data which we have to accept because the underlaying data generation process is stochastic in nature. In a pragmatic view, nature isn&rsquo;t deterministic and some examples of random processes that lead to aleatoric uncertainty are:</p>
<ul>
<li>Throwing a dice.</li>
<li>Firing an arrow with exactly the same starting conditions (the vibrations, wind, air pressure all may lead to a slightly different result).</li>
<li>The cards you are dealt in a poker game.</li>
</ul>
<p>Aleatory can have two flavors, being <strong>homoscedastic</strong> and <strong>heteroscedastic</strong>.</p>
<h3 id="homoscedastic">Homoscedastic</h3>
<p>We often assume homoscedastic uncertainty. For example in the model definition of linear regression $y = X \beta + \epsilon$ we incorporate $\epsilon$ for the noise in the data. In linear regression, $\epsilon$ is not dependent on $X$ and is therefore assumed to be constant.</p>
<figure><img src="../../../../../img/post-27-vi-from-scratch/homoscedastic.png"/><figcaption>
            <h4>Example of homoscedastic uncertainty. [2]</h4>
        </figcaption>
</figure>

<h3 id="heteroscedastic">Heteroscedastic</h3>
<p>If the aleatoric uncertainty is dependent on $X$, we speak of heteroscedastic uncertainty. This was the case in the example we&rsquo;ve used above. The figure below shows another example of heteroscedastic uncertainty.</p>
<figure><img src="../../../../../img/post-27-vi-from-scratch/heteroscedastic.png"/><figcaption>
            <h4>Example of heteroscedastic uncertainty. [2]</h4>
        </figcaption>
</figure>

<h3 id="epistemic-uncertainty">Epistemic uncertainty</h3>
<p>The second flavor of uncertainty is epistemic uncertainty. We as algorithm designers have influence on this type of uncertainty. We can actually reduce it, or make it much worse by our decisions. For instance, the way of bootstrapping the data when splitting test, train, and validation sets had influence on the parameters we fit. If we bootstrap differently, we end up with different parameter values, how certain can we be that these are correct?
Epistemic uncertainty can be reduced by acquiring more data, designing better models, or by incorporating better features.</p>
<h2 id="bayes-by-backprop">Bayes by backprop</h2>
<p>In the next part of this post we&rsquo;ll show an example of modelling epistemic uncertainty with variational inference. The implementation is according to <a href="https://arxiv.org/abs/1505.05424">this paper [3]</a>. We will now be modelling the weights $w$ of the neural network with distributions. A priori, our bayesian model consists of the following prior and likelihood.</p>
<div>
$$ 
\begin{eqnarray}
w &\sim&  \mathcal{N}(0, 1) \\
y &\sim&  P(y|x, w)
\end{eqnarray}
$$
</div>
<p>Again, the posterior $P(w|y, x)$ is intractable. So we define a variational distribution $Q_{\theta}(w)$. The theory of variational inference is actually exactly the same as we&rsquo;ve defined in the first part of the post. For convenience reasons we redefine the ELBO as defined in (eq. $\ref{eq:elbo}$) in a form used in [3]. If we multiply the ELBO with $-1$, we obtain a cost function that is called the <strong>variational free energy</strong>.</p>
<p>\begin{equation} \mathcal{F(D, \theta)}= D_{KL}(Q(Z|\theta) || P(Z)) - E_{Z \sim Q}[\log P(D|Z)] \label{eq:vfe} \end{equation}</p>
<h2 id="single-bayesian-layer">Single Bayesian layer</h2>
<p>Just as with the model we have defined earlier, we will approximate all the terms in (eq. $\ref{eq:vfe}$) by sampling $z \sim Q(Z)$. The KL-divergence is not dependent on $D$, and can therefore be computed at the moment of sampling $z$. We will use this insight now as we will make a Bayesian neural network layer in pytorch.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">LinearVariational</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Mean field approximation of nn.Linear
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, in_features, out_features, parent, n_batches, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>in_features <span style="color:#f92672">=</span> in_features
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>out_features <span style="color:#f92672">=</span> out_features
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>include_bias <span style="color:#f92672">=</span> bias        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>parent <span style="color:#f92672">=</span> parent
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>n_batches <span style="color:#f92672">=</span> n_batches
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> getattr(parent, <span style="color:#e6db74">&#39;accumulated_kl_div&#39;</span>, <span style="color:#66d9ef">None</span>) <span style="color:#f92672">is</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            parent<span style="color:#f92672">.</span>accumulated_kl_div <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Initialize the variational parameters.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 𝑄(𝑤)=N(𝜇_𝜃,𝜎2_𝜃)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Do some random initialization with 𝜎=0.001</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>w_mu <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>FloatTensor(in_features, out_features)<span style="color:#f92672">.</span>normal_(mean<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, std<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># proxy for variance</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># log(1 + exp(ρ))◦ eps</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>w_p <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>FloatTensor(in_features, out_features)<span style="color:#f92672">.</span>normal_(mean<span style="color:#f92672">=-</span><span style="color:#ae81ff">2.5</span>, std<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>include_bias:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>b_mu <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(
</span></span><span style="display:flex;"><span>                torch<span style="color:#f92672">.</span>zeros(out_features)
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># proxy for variance</span>
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>b_p <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(
</span></span><span style="display:flex;"><span>                torch<span style="color:#f92672">.</span>zeros(out_features)
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">reparameterize</span>(self, mu, p):
</span></span><span style="display:flex;"><span>        sigma <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>log(<span style="color:#ae81ff">1</span> <span style="color:#f92672">+</span> torch<span style="color:#f92672">.</span>exp(p)) 
</span></span><span style="display:flex;"><span>        eps <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn_like(sigma)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> mu <span style="color:#f92672">+</span> (eps <span style="color:#f92672">*</span> sigma)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">kl_divergence</span>(self, z, mu_theta, p_theta, prior_sd<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>        log_prior <span style="color:#f92672">=</span> dist<span style="color:#f92672">.</span>Normal(<span style="color:#ae81ff">0</span>, prior_sd)<span style="color:#f92672">.</span>log_prob(z) 
</span></span><span style="display:flex;"><span>        log_p_q <span style="color:#f92672">=</span> dist<span style="color:#f92672">.</span>Normal(mu_theta, torch<span style="color:#f92672">.</span>log(<span style="color:#ae81ff">1</span> <span style="color:#f92672">+</span> torch<span style="color:#f92672">.</span>exp(p_theta)))<span style="color:#f92672">.</span>log_prob(z) 
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> (log_p_q <span style="color:#f92672">-</span> log_prior)<span style="color:#f92672">.</span>sum() <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>n_batches
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        w <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>reparameterize(self<span style="color:#f92672">.</span>w_mu, self<span style="color:#f92672">.</span>w_p)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>include_bias:
</span></span><span style="display:flex;"><span>            b <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>reparameterize(self<span style="color:#f92672">.</span>b_mu, self<span style="color:#f92672">.</span>b_p)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            b <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        z <span style="color:#f92672">=</span> x <span style="color:#f92672">@</span> w <span style="color:#f92672">+</span> b
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>parent<span style="color:#f92672">.</span>accumulated_kl_div <span style="color:#f92672">+=</span> self<span style="color:#f92672">.</span>kl_divergence(w, 
</span></span><span style="display:flex;"><span>                                                             self<span style="color:#f92672">.</span>w_mu,
</span></span><span style="display:flex;"><span>                                                             self<span style="color:#f92672">.</span>w_p, 
</span></span><span style="display:flex;"><span>                                                             )
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>include_bias:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>parent<span style="color:#f92672">.</span>accumulated_kl_div <span style="color:#f92672">+=</span> self<span style="color:#f92672">.</span>kl_divergence(b, 
</span></span><span style="display:flex;"><span>                                                                 self<span style="color:#f92672">.</span>b_mu, 
</span></span><span style="display:flex;"><span>                                                                 self<span style="color:#f92672">.</span>b_p,
</span></span><span style="display:flex;"><span>                                                                 )
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> z
</span></span><span style="display:flex;"><span>            
</span></span></code></pre></div><p>The code snippet above shows the implementation of the variational linear layer. The <code>__init__</code> method initializes the variation parameters $\mu_{w}$ and $p_{w}$. In the <code>forward</code> method we sample the weights $w \sim \mathcal{N}(\mu_{w}, \text{diag}(\log(1 + e^{p_w}) )$ and the biases $b \sim \mathcal{N}(\mu_{b}, \text{diag}(\log(1 + e^{p_b}) )$. With these sampled neural networks parameters we do the forward pass of that layer $z = xw + b$. As discussed, we also compute the KL-divergence in the <code>forward</code> method as we don&rsquo;t require any target variable to determine this quantity.</p>
<h3 id="kl-re-weighting">KL re-weighting</h3>
<p>When optimizing with stochastic gradient descent, the KL-divergence in term in (eq. $\ref{eq:vfe}$) needs to be weighed by $\frac{1}{M}$, where $M$ is the number of mini-batches per epoch.</p>
<h2 id="bayesian-neural-network">Bayesian neural network</h2>
<p>This <code>LinearVariational</code> is the gist of a Bayesian neural network optimized with variational inference. In the code snippet below, we implement the same network as before. The only difference in the previous implementation is an auxiliary <code>dataclass</code> that will accumulate the KL-divergences of the variational layers. The code snippets below shows the final implementation, the loss function and the train loop.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#a6e22e">@dataclass</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">KL</span>:
</span></span><span style="display:flex;"><span>    accumulated_kl_div <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Model</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, in_size, hidden_size, out_size, n_batches):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>kl_loss <span style="color:#f92672">=</span> KL
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layers <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            LinearVariational(in_size, hidden_size, self<span style="color:#f92672">.</span>kl_loss, n_batches),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            LinearVariational(hidden_size, hidden_size, self<span style="color:#f92672">.</span>kl_loss, n_batches),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            LinearVariational(hidden_size, out_size, self<span style="color:#f92672">.</span>kl_loss, n_batches)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">@property</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">accumulated_kl_div</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>kl_loss<span style="color:#f92672">.</span>accumulated_kl_div
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">reset_kl_div</span>(self):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>kl_loss<span style="color:#f92672">.</span>accumulated_kl_div <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>layers(x)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">2000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">det_loss</span>(y, y_pred, model):
</span></span><span style="display:flex;"><span>    batch_size <span style="color:#f92672">=</span> y<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>    reconstruction_error <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>dist<span style="color:#f92672">.</span>Normal(y_pred, <span style="color:#ae81ff">.1</span>)<span style="color:#f92672">.</span>log_prob(y)<span style="color:#f92672">.</span>sum()
</span></span><span style="display:flex;"><span>    kl <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>accumulated_kl_div
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>reset_kl_div()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> reconstruction_error <span style="color:#f92672">+</span> kl
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>m <span style="color:#f92672">=</span> Model(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">1</span>, n_batches<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>optim <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(m<span style="color:#f92672">.</span>parameters(), lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epochs):
</span></span><span style="display:flex;"><span>    optim<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>    y_pred <span style="color:#f92672">=</span> m(X)
</span></span><span style="display:flex;"><span>    loss <span style="color:#f92672">=</span> det_loss(y_pred, Y, m)
</span></span><span style="display:flex;"><span>    loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>    optim<span style="color:#f92672">.</span>step()
</span></span></code></pre></div><h2 id="epistemic-uncertainty-1">Epistemic uncertainty</h2>
<p>Below we evaluate the trained model by taking 1000 samples per data point. These samples are used to approximate quantities of the posterior predictive distribution such as the mean and the $\{0.05, 0.95 \}$ quantiles. Intuitively, we can think of each 1 of the 1000 samples as a different neural network with slightly different parameters.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>    trace <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([m(X)<span style="color:#f92672">.</span>flatten()<span style="color:#f92672">.</span>numpy() <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1000</span>)])<span style="color:#f92672">.</span>T
</span></span><span style="display:flex;"><span>q_25, q_95 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>quantile(trace, [<span style="color:#ae81ff">0.05</span>, <span style="color:#ae81ff">0.95</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">6</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(X, trace<span style="color:#f92672">.</span>mean(<span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(X, Y)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>fill_between(X<span style="color:#f92672">.</span>flatten(), q_25, q_95, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)
</span></span></code></pre></div><figure><img src="../../../../../img/post-27-vi-from-scratch/epistemic.png"/><figcaption>
            <h4>Results of the Bayesian neural network optimized w/ variation inference.</h4>
        </figcaption>
</figure>

<p>We see we didn&rsquo;t model the aleatoric uncertainty. What we&rsquo;ve captured now is the uncertainty of the true mean value, $E[Y|X]$.</p>
<h2 id="final-words">Final words</h2>
<p>This post we&rsquo;ve implemented variational inference in two flavors. In one we&rsquo;ve modelled aleatoric uncertainty and got insight in the changing variance of $y \sim P(Y|X)$. The second implementation was a fully bayesian neural network and resulted in epistemic uncertainty. In this implementation we were not interested in the uncertainty in the data, but in the uncertainty of our model. Variational inference seems to be a powerful, modular approach to enrich deep learning with uncertainty values.</p>
<p>I don&rsquo;t believe I have to stress the importance of modeling uncertainty, yet in most machine learning models uncertainty is regarded secundary. <a href="https://www.yuritan.nl/posts/prediction_uncertainty/">Yu Ri Tan</a> has got a very nice blog post on this topic. He explores how we can get insight in the uncertainty of our models in a frequentistic manner. Do read!</p>
<h2 id="references">References</h2>
<p>  [1] Kingma &amp; Welling (2013, Dec 20) <em>Auto-Encoding Variational Bayes</em>. Retrieved from <a href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</a> <br>
  [2] Gal, Y. (2016, Feb 18) <em>HeteroscedasticDropoutUncertainty</em>. Retrieved from <a href="https://github.com/yaringal/HeteroscedasticDropoutUncertainty">https://github.com/yaringal/HeteroscedasticDropoutUncertainty</a> <br>
  [3] Blundell, Cornebise, Kavukcioglu &amp; Wierstra (2015, May 20) <em>Weight Uncertainty in Neural Networks</em>. Retrieved from <a href="https://arxiv.org/abs/1505.05424">https://arxiv.org/abs/1505.05424</a><br></p>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
  </script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<head>
<style>

.formula-wrap {
overflow-x: scroll;
}

</style>

    </div>
    
    
  </div>
</section>

<section class="section">
  <div class="container">
    <aside><div id="disqus_thread"></div></aside>
    <script type="text/javascript">
      var disqus_shortname = 'www-ritchievink-com';
      (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
  </div>
</section>


<section class="section">
  <div class="container has-text-centered">
    <p>(c) 2020 Ritchie Vink.</p>
  </div>
</section>

<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.0/build/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/javascript">
    if (window.location.href.indexOf('localhost') < 0) {
	    var _gaq = _gaq || [];
	    _gaq.push(['_setAccount', 'UA-83196691-2']);
	    _gaq.push(['_trackPageview']);

	    (function() {
		var ga = document.createElement('script');
		ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
		    'http://www') + '.google-analytics.com/ga.js';
		ga.setAttribute('async', 'true');
		document.documentElement.firstChild.appendChild(ga);
	    })();
}
</script>




</body>
