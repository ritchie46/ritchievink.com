<!DOCTYPE html>
<html lang="en-EN">
<head>
	<meta name="generator" content="Hugo 0.118.2">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta content="keyword 1, keyword 2, keyword 3" name="keywords">
<meta content="Ritchie Vink" name="author">
<meta property="og:title" content="Ritchie Vink">
<meta property="og:url" content="https://www.ritchievink.com/">
<meta property="og:description" content="">
<meta property="og:type" content="website" />



<title>Ritchie Vink</title>

<link rel="stylesheet" href="https://www.ritchievink.com//css/style.css">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />

<link rel="stylesheet"
      href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.0/build/styles/default.min.css">

</head>

<section class="section">
  <div class="container">
    <nav class="nav">

 <img src="./profile.jpg" alt="Avatar" style="margin-right: 1em" height="100px"> 
      <div class="nav-left" style="flex-basis: auto;">

        <a class="nav-item" href="https://www.ritchievink.com/"><h1 class="title is-4">Ritchie Vink</h1></a>
      <nav class="nav-item level is-mobile">
          <a class="level-item" href="./tags">
            tags
          </a>
          
          
          <a class="level-item" href="https://www.ritchievink.com/about/">
            about
          </a>
          
          <a class="level-item" href="https://www.ritchievink.com/anastruct/">
            anastruct
          </a>
          
        </nav>
      </div>
      <div class="nav-right">
        <nav class="nav-item level is-mobile">
          
          <a class="level-item" href="https://github.com/ritchie46" target="_blank">
            <span class="icon">
              <i class="fa fa-github"></i>
            </span>
          </a>
          
          <a class="level-item" href="https://linkedin.com/in/ritchievink/" target="_blank">
            <span class="icon">
              <i class="fa fa-linkedin-square"></i>
            </span>
          </a>
          
          <a class="level-item" href="https://www.ritchievink.com/index.xml" target="_blank">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>
          </a>
          
        </nav>
      </div>
    </nav>
  </div>
</section>


<section class="section">
  <div class="container">
    
    <article>
      <h1 class="title"><a href="https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/">I wrote one of the fastest DataFrame libraries</a></h1>
      <h2 class="subtitle is-5">February 28, 2021</h2>
      
        <div class="tags">
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/computer-science">computer science</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/python">python</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/rust">rust</a>
    
</div>

      


 <img src="https://www.ritchievink.com/img/post-34-polars/polars.webp">


      <div class="content">
        1. Introduction At the time of writing this, the coronavirus has been in our country for a year, which means I have been sitting at home for a very long time. At the start of the pandemic, I had a few pet projects in Rust under my belt and I noticed that the &ldquo;are we DataFrame yet&rdquo;, wasn&rsquo;t anywhere near my satisfaction. So I wondered if I could make a minimalistic crate that solved a specific use case of mine.
        
        <a class="button" href="https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/" style="height:28px">
          Read more
          <span class="icon is-small">
            <i class="fa fa-angle-double-right"></i>
          </span>
        </a>
        
      </div>
    </article>
    
    <article>
      <h1 class="title"><a href="https://www.ritchievink.com/blog/2020/04/07/sparse-neural-networks-and-hash-tables-with-locality-sensitive-hashing/">Sparse neural networks and hash tables with Locality Sensitive Hashing</a></h1>
      <h2 class="subtitle is-5">April 7, 2020</h2>
      
        <div class="tags">
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/machine-learning">machine learning</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/rust">rust</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/optimization">optimization</a>
    
</div>

      


 <img src="https://www.ritchievink.com/img/post-32-lsh-nn/file_cabinet.jpg">


      <div class="content">
        This is post was a real eye-opener for me with regard to the methods we can use to train neural networks. A colleague pointed me to the SLIDE[1] paper. Chen &amp; et al. discussed outperforming a Tesla V100 GPU with a 44 core CPU, by a factor of 3.5, when training large neural networks with millions of parameters. Training any neural network requires many, many, many tensor operations, mostly in the form of matrix multiplications.
        
        <a class="button" href="https://www.ritchievink.com/blog/2020/04/07/sparse-neural-networks-and-hash-tables-with-locality-sensitive-hashing/" style="height:28px">
          Read more
          <span class="icon is-small">
            <i class="fa fa-angle-double-right"></i>
          </span>
        </a>
        
      </div>
    </article>
    
    <article>
      <h1 class="title"><a href="https://www.ritchievink.com/blog/2019/11/12/another-normalizing-flow-inverse-autoregressive-flows/">Another normalizing flow: Inverse Autoregressive Flows</a></h1>
      <h2 class="subtitle is-5">November 12, 2019</h2>
      
        <div class="tags">
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/machine-learning">machine learning</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/python">python</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/deep-learning">deep-learning</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/bayesian">bayesian</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/pytorch">pytorch</a>
    
</div>

      


 <img src="https://www.ritchievink.com/img/post-30-iaf/og_image.jpg">


      <div class="content">
        This post we will explore a type of normalizing flow called **Inverse Autoregressive Flow**. A composition (flow) of transformations, while preserving the constraints of a probability distribution (normalizing), can help us obtain highly correlated variational distributions. Don&rsquo;t repeat yourself
If what was mentioned in the previous lines didn&rsquo;t ring a bell, do first read these posts: variational inference and normalizing flows. This post could really be seen as an extension of the latter.
        
        <a class="button" href="https://www.ritchievink.com/blog/2019/11/12/another-normalizing-flow-inverse-autoregressive-flows/" style="height:28px">
          Read more
          <span class="icon is-small">
            <i class="fa fa-angle-double-right"></i>
          </span>
        </a>
        
      </div>
    </article>
    
    <article>
      <h1 class="title"><a href="https://www.ritchievink.com/blog/2019/10/25/distribution-estimation-with-masked-autoencoders/">Distribution estimation with Masked Autoencoders</a></h1>
      <h2 class="subtitle is-5">October 25, 2019</h2>
      
        <div class="tags">
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/machine-learning">machine learning</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/python">python</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/deep-learning">deep-learning</a>
    
</div>

      


 <img src="https://www.ritchievink.com/img/post-29-made/og_image.jpg">


      <div class="content">
        Four of my last five blog posts were more or less related to Baysian inference with variational methods. I had some momentum, and I wanted to use the traction I gained to do another post (which will come!) on enhancing variational methods with Inverse Autoregressive Flows (IAF), but first I have to get something different out of the way.
In the paper describing IAF, they refer to an autoregressive neural network (and further assume his to be clear knowlegde).
        
        <a class="button" href="https://www.ritchievink.com/blog/2019/10/25/distribution-estimation-with-masked-autoencoders/" style="height:28px">
          Read more
          <span class="icon is-small">
            <i class="fa fa-angle-double-right"></i>
          </span>
        </a>
        
      </div>
    </article>
    
    <article>
      <h1 class="title"><a href="https://www.ritchievink.com/blog/2019/10/11/sculpting-distributions-with-normalizing-flows/">Sculpting distributions with Normalizing Flows</a></h1>
      <h2 class="subtitle is-5">October 11, 2019</h2>
      
        <div class="tags">
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/machine-learning">machine learning</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/python">python</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/bayesian">bayesian</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/optimization">optimization</a>
    
</div>

      


 <img src="https://www.ritchievink.com/img/post-28-norm-flows/og_image.jpg">


      <div class="content">
        Last posts we&rsquo;ve investigated Bayesian inference through variational inference (post 1/post 2). In Bayesian inference, we often define models with some unknown model parameters $Z$, or latent stochastic variables $Z$. Given this model and some observed data points $D = \{ D_1, D_2, \dots, D_n \} $, we are interested in the true posterior distribution $P(Z|D)$. This posterior is often intractable and the general idea was to forgo the quest of obtaining the true posterior, but to accept that we are bounded to some easily parameterizable approximate posteriors $^*Q(z)$, which we called variational distributions.
        
        <a class="button" href="https://www.ritchievink.com/blog/2019/10/11/sculpting-distributions-with-normalizing-flows/" style="height:28px">
          Read more
          <span class="icon is-small">
            <i class="fa fa-angle-double-right"></i>
          </span>
        </a>
        
      </div>
    </article>
    
    <article>
      <h1 class="title"><a href="https://www.ritchievink.com/blog/2019/09/16/variational-inference-from-scratch/">Variational inference from scratch</a></h1>
      <h2 class="subtitle is-5">September 16, 2019</h2>
      
        <div class="tags">
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/algorithm-breakdown">algorithm breakdown</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/machine-learning">machine learning</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/python">python</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/bayesian">bayesian</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/optimization">optimization</a>
    
</div>

      


 <img src="https://www.ritchievink.com/img/post-27-vi-from-scratch/soundboard.jpg">


      <div class="content">
        In the posts Expectation Maximization and Bayesian inference; How we are able to chase the Posterior, we laid the mathematical foundation of variational inference. This post we will continue on that foundation and implement variational inference in Pytorch. If you are not familiar with the basis, I&rsquo;d recommend reading these posts to get you up to speed.
This post we&rsquo;ll model a probablistic layer as output layer of a neural network.
        
        <a class="button" href="https://www.ritchievink.com/blog/2019/09/16/variational-inference-from-scratch/" style="height:28px">
          Read more
          <span class="icon is-small">
            <i class="fa fa-angle-double-right"></i>
          </span>
        </a>
        
      </div>
    </article>
    
    <article>
      <h1 class="title"><a href="https://www.ritchievink.com/blog/2019/08/25/algorithm-breakdown-bayesian-optimization/">Algorithm Breakdown: Bayesian Optimization</a></h1>
      <h2 class="subtitle is-5">August 25, 2019</h2>
      
        <div class="tags">
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/algorithm-breakdown">algorithm breakdown</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/machine-learning">machine learning</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/python">python</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/gaussian-processes">gaussian processes</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/bayesian">bayesian</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/optimization">optimization</a>
    
</div>

      


 <img src="https://www.ritchievink.com/img/post-26/explore-forest.jpg">


      <div class="content">
        Not that long ago I wrote an introduction post on Gaussian Processes (GP&rsquo;s), a regression technique where we condition a Gaussian prior distribution over functions on observed data. GP&rsquo;s can model any function that is possible within a given prior distribution. And we don&rsquo;t get a function $f$, we get a whole posterior distribution of functions $P(f|X)$.
This of course, sounds very cool and all, but there is no free lunch.
        
        <a class="button" href="https://www.ritchievink.com/blog/2019/08/25/algorithm-breakdown-bayesian-optimization/" style="height:28px">
          Read more
          <span class="icon is-small">
            <i class="fa fa-angle-double-right"></i>
          </span>
        </a>
        
      </div>
    </article>
    
    <article>
      <h1 class="title"><a href="https://www.ritchievink.com/blog/2019/06/10/bayesian-inference-how-we-are-able-to-chase-the-posterior/">Bayesian inference; How we are able to chase the Posterior</a></h1>
      <h2 class="subtitle is-5">June 10, 2019</h2>
      
        <div class="tags">
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/machine-learning">machine learning</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/python">python</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/bayesian">bayesian</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/pymc3">pymc3</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/pyro">pyro</a>
    
</div>

      


 <img src="https://www.ritchievink.com/img/post-25-vi/variational_inference.jpg">


      <div class="content">
        Bayesian modeling! Every introduction on that topic starts with a quick conclusion that finding the posterior distribution often is computationally intractable. Last post I looked at Expectation Maximization, which is a solution of this computational intractability for a set of models. However, for most models, it isn&rsquo;t. This post I will take a formal definition of the problem (As I&rsquo;ve skipped that in the Expectation Maximization post) and we&rsquo;ll look at two solutions that help us tackle this problem; Markov Chain Monte Carlo and Variational Inference.
        
        <a class="button" href="https://www.ritchievink.com/blog/2019/06/10/bayesian-inference-how-we-are-able-to-chase-the-posterior/" style="height:28px">
          Read more
          <span class="icon is-small">
            <i class="fa fa-angle-double-right"></i>
          </span>
        </a>
        
      </div>
    </article>
    
    <article>
      <h1 class="title"><a href="https://www.ritchievink.com/blog/2019/05/24/algorithm-breakdown-expectation-maximization/">Algorithm Breakdown: Expectation Maximization</a></h1>
      <h2 class="subtitle is-5">May 24, 2019</h2>
      
        <div class="tags">
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/machine-learning">machine learning</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/python">python</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/clustering">clustering</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/bayesian">bayesian</a>
    
</div>

      


 <img src="https://www.ritchievink.com/img/post-24-em/grand_canyon.jpg">


      <div class="content">
        I wanted to learn something about variational inference, a technique used to approximate the posterior distribution in Bayesian modeling. However, during my research, I bounced on quite some mathematics that led me to another optimization technique called Expectation Maximization. I believe the theory behind this algorithm is a stepping stone to the mathematics behind variational inference. So we tackle the problems one problem at a time!
The first part of this post will focus on Gaussian Mixture Models, as expectation maximization is the standard optimization algorithm for these models.
        
        <a class="button" href="https://www.ritchievink.com/blog/2019/05/24/algorithm-breakdown-expectation-maximization/" style="height:28px">
          Read more
          <span class="icon is-small">
            <i class="fa fa-angle-double-right"></i>
          </span>
        </a>
        
      </div>
    </article>
    
    <article>
      <h1 class="title"><a href="https://www.ritchievink.com/blog/2019/04/02/fully-automated-soil-classification-with-a-convolutional-neural-network-and-location-embeddings/">Fully automated soil classification with a Convolutional Neural Network and Location embeddings</a></h1>
      <h2 class="subtitle is-5">April 2, 2019</h2>
      
        <div class="tags">
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/engineering">engineering</a>
    
        <a class="button is-link" href="https://www.ritchievink.com/tags/python">python</a>
    
</div>

      


 <img src="https://www.ritchievink.com/img/soil-classification/header2.jpg">


      <div class="content">
        Soil classification is, in practice, a human process. A geotechnical engineer interprets results from a Cone Penetration Test and comes up with a plausible depiction of the existing soil layers. These interpretations will often be used throughout a project and are input for many following calculations.
Just as the poliovirus, the process of manually mapping data from $x$ to $y$, belongs to the list of things that humanity tries to eradicate from earth.
        
        <a class="button" href="https://www.ritchievink.com/blog/2019/04/02/fully-automated-soil-classification-with-a-convolutional-neural-network-and-location-embeddings/" style="height:28px">
          Read more
          <span class="icon is-small">
            <i class="fa fa-angle-double-right"></i>
          </span>
        </a>
        
      </div>
    </article>
    
  </div>
</section>
<section class="section">
  <div class="container">
    <nav class="level is-mobile">
      <div class="level-left">
        <div class="level-item">
          
        </div>
      </div>
      <div class="level-right is-marginless">
        <div class="level-item">
          
          <a class="button" href="./page/2/">
            Older
            <span class="icon is-small is-marginless">
              <i class="fa fa-angle-right"></i>
            </span>
          </a>
          
        </div>
      </div>
    </nav>
  </div>
</section>

<section class="section">
  <div class="container has-text-centered">
    <p>(c) 2020 Ritchie Vink.</p>
  </div>
</section>

<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.0/build/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/javascript">
    if (window.location.href.indexOf('localhost') < 0) {
	    var _gaq = _gaq || [];
	    _gaq.push(['_setAccount', 'UA-83196691-2']);
	    _gaq.push(['_trackPageview']);

	    (function() {
		var ga = document.createElement('script');
		ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
		    'http://www') + '.google-analytics.com/ga.js';
		ga.setAttribute('async', 'true');
		document.documentElement.firstChild.appendChild(ga);
	    })();
}
</script>





